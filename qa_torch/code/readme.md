### 比赛：Tweet Sentiment Extraction
### 链接：https://www.kaggle.com/c/tweet-sentiment-extraction

### 介绍：
比赛给出了tweet句子和情感标签（积极，消极，中性），要求预测出决定句子情感的主要段落是什么。问题难点在于有一些句子有很奇怪的断裂，开始或结束的单词会被截断。

### 我的解决方案
我使用了一个RoBerta_base模型，  
* 数据格式：input_ids = [0] + [sentiment_id[sentiment]] + [2] + [2] + input_ids_orig + [2]， 
* 第一个0是开始标志，然后是情绪类别，三种，然后是2，表示结束，然后再是2，表示开始，input_ids_orig表示句子被编码后的id，最后一个2表示结束。targets_start是在对应开始的位置标1，targets_end是在对* 应结束的位置标1.在数据类中还要返回原始的数据，供后面的评估函数调用。
* 模型结构：取倒数两个隐层输出，接dropout然后全连接两个输出，平均一下。
* 损失函数：标签平滑的交叉熵损失函数。start和end损失取平均作为总的损失函数。
* 评估矩阵：做了一个处理，所有中性的类别，直接用原长代替。其他的计算jaccard分数。
* 训练：采用5折交叉验证。设置早停，当最大值超过两轮不在增长时，停止训练。EPOCHS设置为5.MAX_LEN 设置为128，因为句子中很少有超过128的句子。  

### 总结：
* 1，没有花时间好好的做融合。也没有更换多个种子来检验结果，这个比赛的数据集不大，用kernel的GPU也可以完成。
* 2，对于一些字符的偏移问题，一直没有解决这个问题。之后有人给出了解释，一种是连续的空格，也就是text在标记时先删除了连续空格，导致selected_text标注出错。
* 3，也有人在一级的预测模型上又构建了二级模型，进行字符级别的预测。或采用Bean Search搜索最大的几个可能性，或者将start可能与end可能性相乘，同时进行预测。
* 4，这个比赛最适合的模型时RoBerta模型，据说BertTweet模型也挺有用。
